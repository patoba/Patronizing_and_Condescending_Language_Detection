{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anapm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anapm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RemoveWords, GetTags, GetBase, Limpieza, common_tag_list, Tokenize, UnTokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\" Just like we received migrants fleeing El Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>@@9382277</td>\n",
       "      <td>in-need</td>\n",
       "      <td>in</td>\n",
       "      <td>To bring down high blood sugar levels , insuli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>@@7562079</td>\n",
       "      <td>refugee</td>\n",
       "      <td>za</td>\n",
       "      <td>The European Union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>@@23663488</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>nz</td>\n",
       "      <td>\" They 're either hopeless for being beaten by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>@@3449225</td>\n",
       "      <td>homeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>NUEVA ERA , Ilocos Norte - No family shall be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1         2   3  \\\n",
       "0  5   @@1494111   refugee  ca   \n",
       "1  6   @@9382277   in-need  in   \n",
       "2  7   @@7562079   refugee  za   \n",
       "3  8  @@23663488  hopeless  nz   \n",
       "4  9   @@3449225  homeless  ph   \n",
       "\n",
       "                                                   4  5  \n",
       "0  \" Just like we received migrants fleeing El Sa...  0  \n",
       "1  To bring down high blood sugar levels , insuli...  0  \n",
       "2  The European Union is making an historic mista...  0  \n",
       "3  \" They 're either hopeless for being beaten by...  0  \n",
       "4  NUEVA ERA , Ilocos Norte - No family shall be ...  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'datasets\\\\dontpatronizeme_pcl.tsv', skiprows=4, sep='\\t', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [Just, like, we, received, migrants, fleeing, ...\n",
      "1        [To, bring, down, high, blood, sugar, levels, ...\n",
      "2        [The, European, Union, is, making, an, histori...\n",
      "3        [Theyre, either, hopeless, for, being, beaten,...\n",
      "4        [NUEVA, ERA, Ilocos, Norte, -, No, family, sha...\n",
      "                               ...                        \n",
      "10460    [Sri, Lankan, norms, and, culture, inhibit, wo...\n",
      "10461    [He, added, that, the, AFP, will, continue, to...\n",
      "10462    [She, has, one, huge, platform, and, informati...\n",
      "10463    [Anja, Ringgren, Loven, I, cant, find, a, word...\n",
      "10464    [Guinness, World, Record, of, lbs, of, -layer,...\n",
      "Name: 4, Length: 10464, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['text','PCL'],\n",
    "                 data = [\n",
    "                     [['Murder','rate','has','been','raising','in','the','last','5','years'],0],\n",
    "                     [['we','have','to','take','care','of','the','lovely','women'],1],\n",
    "                     [['1st','minister','announced','yesterday','a','new','policy'],0],\n",
    "                     [['the','inmigrants','have','endured','the','worst','but','they','smile','everyday'],1],\n",
    "                     [['more','cases','of','familiar','violence','have','been','reported'],0],\n",
    "                     [['Sri','Lankan','norms','and','culture','inhibit','women','development'],0],\n",
    "                     [['Anja','Ringgren','Loven','I',\"can't\",'find','a','word','to','describe'],1],\n",
    "                     [['Is','the','raising','of','prices','the','main','reason','for','vulnerability'],0],\n",
    "                     [['In','Lybia','today','there','are','countless','number','of'],0],\n",
    "                 ])\n",
    "X = df.text\n",
    "y = df.PCL\n",
    "pipe1 = Pipeline(steps=[('limpieza', Limpieza()),\n",
    "                         ('tokenize', Tokenize()),\n",
    "                        ('remove_stopwords', RemoveWords()),\n",
    "                        ('obtener_tags', GetTags(tag_list = common_tag_list)),\n",
    "                         ('get_base', GetBase()),\n",
    "                         ('untokenize', UnTokenize()),\n",
    "                         ('tfidf', TfidfVectorizer())\n",
    "                         ])\n",
    "res = pipe1.fit_transform(data.iloc[:,4],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"|,|!|:|\\d|\\.|'\n",
      "0        [, Just, like, we, received, migrants, fleeing...\n",
      "1        [To, bring, down, high, blood, sugar, levels, ...\n",
      "2        [The, European, Union, is, making, an, histori...\n",
      "3        [, Theyre, either, hopeless, for, being, beate...\n",
      "4        [NUEVA, ERA, Ilocos, Norte, -, No, family, sha...\n",
      "                               ...                        \n",
      "10460    [Sri, Lankan, norms, and, culture, inhibit, wo...\n",
      "10461    [He, added, that, the, AFP, will, continue, to...\n",
      "10462    [, She, has, one, huge, platform, and, informa...\n",
      "10463    [, Anja, Ringgren, Loven, I, cant, find, a, wo...\n",
      "10464    [, Guinness, World, Record, of, lbs, of, -laye...\n",
      "Name: 4, Length: 10464, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [, like, received, migrants, fleeing, El, Salv...\n",
       "1        [bring, high, blood, sugar, levels, insulin, n...\n",
       "2        [European, Union, making, historic, mistake, h...\n",
       "3        [, Theyre, either, hopeless, beaten, -year-old...\n",
       "4        [NUEVA, ERA, Ilocos, Norte, -, family, shall, ...\n",
       "                               ...                        \n",
       "10460    [Sri, Lankan, norms, culture, inhibit, women, ...\n",
       "10461    [added, AFP, continue, bank, application, whol...\n",
       "10462    [, one, huge, platform, information, go, place...\n",
       "10463    [, Anja, Ringgren, Loven, cant, find, word, de...\n",
       "10464    [, Guinness, World, Record, lbs, -layer, munch...\n",
       "Name: 4, Length: 10464, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpi = Limpieza().fit_transform(data.iloc[:,4])\n",
    "remo = RemoveWords().fit_transform(limpi)\n",
    "remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpi.dropna().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(l):\n",
    "    try:\n",
    "        return [w for w in l ]\n",
    "    except:\n",
    "        print(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [, Just, like, we, received, migrants, fleeing...\n",
       "1        [To, bring, down, high, blood, sugar, levels, ...\n",
       "2        [The, European, Union, is, making, an, histori...\n",
       "3        [, Theyre, either, hopeless, for, being, beate...\n",
       "4        [NUEVA, ERA, Ilocos, Norte, -, No, family, sha...\n",
       "                               ...                        \n",
       "10460    [Sri, Lankan, norms, and, culture, inhibit, wo...\n",
       "10461    [He, added, that, the, AFP, will, continue, to...\n",
       "10462    [, She, has, one, huge, platform, and, informa...\n",
       "10463    [, Anja, Ringgren, Loven, I, cant, find, a, wo...\n",
       "10464    [, Guinness, World, Record, of, lbs, of, -laye...\n",
       "Name: 4, Length: 10465, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpi.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpi.to_csv('ejemplo\\\\limpi.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
